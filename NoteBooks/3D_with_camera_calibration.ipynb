{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "2SewQTyzVoBW",
    "outputId": "bc236678-44ec-46df-9f80-1ba476f8ded5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: opencv-python-headless in /opt/anaconda3/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.19.0)\n",
      "Requirement already satisfied: timm in /opt/anaconda3/lib/python3.12/site-packages (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (74.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/lib/python3.12/site-packages (from timm) (0.24.6)\n",
      "Requirement already satisfied: safetensors in /opt/anaconda3/lib/python3.12/site-packages (from timm) (0.4.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python opencv-python-headless torch torchvision timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLNXii85FxHl",
    "outputId": "4384fe29-4f42-45c9-c234-dff02d25cd5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in /opt/anaconda3/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from opencv-contrib-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_RJNZR8V5xt"
   },
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "EC2vVNMIVzdb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsjbVHmhZ7gU",
    "outputId": "c2bc28e0-ba74-455b-e396-b7a61d2964fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ArucoDetector', 'Board', 'CORNER_REFINE_APRILTAG', 'CORNER_REFINE_CONTOUR', 'CORNER_REFINE_NONE', 'CORNER_REFINE_SUBPIX', 'CharucoBoard', 'CharucoDetector', 'CharucoParameters', 'DICT_4X4_100', 'DICT_4X4_1000', 'DICT_4X4_250', 'DICT_4X4_50', 'DICT_5X5_100', 'DICT_5X5_1000', 'DICT_5X5_250', 'DICT_5X5_50', 'DICT_6X6_100', 'DICT_6X6_1000', 'DICT_6X6_250', 'DICT_6X6_50', 'DICT_7X7_100', 'DICT_7X7_1000', 'DICT_7X7_250', 'DICT_7X7_50', 'DICT_APRILTAG_16H5', 'DICT_APRILTAG_16h5', 'DICT_APRILTAG_25H9', 'DICT_APRILTAG_25h9', 'DICT_APRILTAG_36H10', 'DICT_APRILTAG_36H11', 'DICT_APRILTAG_36h10', 'DICT_APRILTAG_36h11', 'DICT_ARUCO_MIP_36H12', 'DICT_ARUCO_MIP_36h12', 'DICT_ARUCO_ORIGINAL', 'DetectorParameters', 'Dictionary', 'Dictionary_getBitsFromByteList', 'Dictionary_getByteListFromBits', 'GridBoard', 'RefineParameters', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_native', 'drawDetectedCornersCharuco', 'drawDetectedDiamonds', 'drawDetectedMarkers', 'extendDictionary', 'generateImageMarker', 'getPredefinedDictionary']\n"
     ]
    }
   ],
   "source": [
    "print(dir(cv2.aruco))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emW4zzz5lECf"
   },
   "source": [
    "#Depth Estimation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aV8Qb9q-lMIF"
   },
   "outputs": [],
   "source": [
    "class DepthEstimationModel:\n",
    "    def __init__(self, model_type=\"MiDaS_small\"):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.transform = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\").small_transform\n",
    "\n",
    "    def estimate_depth(self, img):\n",
    "        input_batch = self.transform(img).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(input_batch)\n",
    "            prediction = torch.nn.functional.interpolate(\n",
    "                prediction.unsqueeze(1),\n",
    "                size=img.shape[:2],\n",
    "                mode=\"bicubic\",\n",
    "                align_corners=False,\n",
    "            ).squeeze()\n",
    "\n",
    "        depth_map = prediction.cpu().numpy()\n",
    "        return cv2.normalize(depth_map, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQqwNOhmpJwK"
   },
   "source": [
    "#Calibrate Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MYxU0tpaS_P",
    "outputId": "82fd6c87-0709-4660-8cf2-100fdbe18ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera calibration successful!\n",
      "Camera Matrix: [[     341.92           0      426.06]\n",
      " [          0      196.29      170.51]\n",
      " [          0           0           1]]\n",
      "Distortion Coefficients: [[   0.061903   -0.073217    0.049853    0.015175    0.011426]]\n"
     ]
    }
   ],
   "source": [
    "def calibrate_camera_with_aruco(video_path):\n",
    "    # Load the predefined dictionary\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_250)\n",
    "    aruco_params = cv2.aruco.DetectorParameters()\n",
    "\n",
    "    # Create ArucoDetector object\n",
    "    detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    all_corners = []  # List to store 2D corners (image points)\n",
    "    all_ids = []      # List to store marker IDs\n",
    "    obj_points = []   # List to store 3D object points\n",
    "\n",
    "    # Define the 3D points for a single marker (assuming square markers)\n",
    "    marker_length = 0.05  # Example marker length (adjust as necessary)\n",
    "\n",
    "    # 3D coordinates for the ArUco marker in real world (z=0 because it's on a plane)\n",
    "    obj_point = np.array([[0, 0, 0],\n",
    "                          [marker_length, 0, 0],\n",
    "                          [marker_length, marker_length, 0],\n",
    "                          [0, marker_length, 0]], dtype=np.float32)\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect ArUco markers\n",
    "        corners, ids, _ = detector.detectMarkers(gray)\n",
    "\n",
    "        if ids is not None:\n",
    "            # Add detected 2D corners and corresponding 3D object points\n",
    "            for i in range(len(ids)):\n",
    "                all_corners.append(corners[i])  # Add 2D corners for this marker\n",
    "                all_ids.append(ids[i])          # Add marker ID\n",
    "                obj_points.append(obj_point)    # Add the same 3D points for each detected marker\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count >= 600:  # Limit to 600 frames for calibration\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Perform camera calibration (now with properly formatted object and image points)\n",
    "    ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        obj_points, all_corners, gray.shape[::-1], None, None\n",
    "    )\n",
    "\n",
    "    if ret:\n",
    "        print(\"Camera calibration successful!\")\n",
    "        return camera_matrix, dist_coeffs\n",
    "    else:\n",
    "        print(\"Camera calibration failed.\")\n",
    "        return None, None\n",
    "\n",
    "# Replace 'your_video.mp4' with your video file path\n",
    "camera_matrix, dist_coeffs = calibrate_camera_with_aruco('ex2.mp4')\n",
    "print(\"Camera Matrix:\", camera_matrix)\n",
    "print(\"Distortion Coefficients:\", dist_coeffs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbmXE9UY-Qv9"
   },
   "source": [
    "#Initialise the video path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UIguR5CLXfXz"
   },
   "outputs": [],
   "source": [
    "# Video capture from file or camera\n",
    "video_path = 'ex2.mp4'  # Replace with 0 for webcam if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ed7ef5FXSWj"
   },
   "source": [
    "#Loading YOLOv5 for Car Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "MlSGh9pHXN-_",
    "outputId": "38aba8b4-3d72-4b82-d78f-c599bbee940e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/shaden/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2024-9-11 Python-3.12.1 torch-2.4.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoShape(\n",
       "  (model): DetectMultiBackend(\n",
       "    (model): DetectionModel(\n",
       "      (model): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Conv(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (4): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (6): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Conv(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (8): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): SPPF(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (10): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (12): Concat()\n",
       "        (13): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (15): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (16): Concat()\n",
       "        (17): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (19): Concat()\n",
       "        (20): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (21): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (22): Concat()\n",
       "        (23): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (24): Detect(\n",
       "          (m): ModuleList(\n",
       "            (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv5 model (for car detection)\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "yolo_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JljZdjGxXbz4"
   },
   "source": [
    "# Initialize depth estimation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.9)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from timm) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from timm) (0.19.0)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from timm) (0.23.2)\n",
      "Requirement already satisfied: safetensors in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from timm) (0.4.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub->timm) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub->timm) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub->timm) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub->timm) (4.12.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->timm) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->timm) (74.1.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision->timm) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision->timm) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch->timm) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip3 install --upgrade pip\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nC1GRsJuldtI",
    "outputId": "cd76e733-3e21-4d56-9b99-1cb70f979a0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/shaden/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/shaden/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /Users/shaden/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "# Initialize depth estimation model\n",
    "depth_model = DepthEstimationModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIIMl_aMXmn7"
   },
   "source": [
    "#Load example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "zZt7XjKzzjkt",
    "outputId": "ad541d48-5917-4f41-fb58-9ead84ee572b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera calibration successful!\n"
     ]
    }
   ],
   "source": [
    "# Calibrate the camera\n",
    "camera_matrix, dist_coeffs = calibrate_camera_with_aruco(video_path)\n",
    "if camera_matrix is None or dist_coeffs is None:\n",
    "    print(\"Camera calibration failed. Exiting.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "B4aVArbOzjJr"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ndFGbWpbEaG",
    "outputId": "77b6e45f-f7c7-48cb-ef70-d006aebd2870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 848x480\n"
     ]
    }
   ],
   "source": [
    "# Get video dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "print(f\"Video dimensions: {width}x{height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yqnGzRJbUaJ"
   },
   "source": [
    "#Codec and create VideoWriter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "S982nGFcbPDS"
   },
   "outputs": [],
   "source": [
    "# Define the codec and create VideoWriter object\n",
    "output_path = 'Output/output_video.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4 files\n",
    "out = cv2.VideoWriter(output_path, fourcc, 20.0, (width, height))  # 20 FPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKCBmG0lYz-s"
   },
   "source": [
    "#Process the video and transform to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Cu3k5rxDY5ld",
    "outputId": "93829adb-b0d3-480f-d3f8-577399851098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing complete. Output saved as 'output_video.mp4'\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Initialize frame count\n",
    "frame_count = 0\n",
    "\n",
    "# Process the video and transform it to 3D\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Estimate depth (assuming your depth model works like this)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    depth_map = depth_model.estimate_depth(img)\n",
    "\n",
    "    # YOLOv5 car detection\n",
    "    results = yolo_model(frame)\n",
    "    detections = results.xyxy[0]\n",
    "\n",
    "    # Filter out cars (YOLOv5 class 'car' is class 2)\n",
    "    car_detections = detections[detections[:, 5] == 2]\n",
    "\n",
    "    # Create a blank canvas for 3D visualization\n",
    "    canvas_3d = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Loop over detected cars\n",
    "    for det in car_detections:\n",
    "        x1, y1, x2, y2, conf, cls = map(int, det[:6])\n",
    "\n",
    "        # Calculate the center of the car\n",
    "        center_x = (x1 + x2) // 2\n",
    "        center_y = (y1 + y2) // 2\n",
    "\n",
    "        # Get the depth value at the center of the car\n",
    "        depth_value = depth_map[center_y, center_x]\n",
    "\n",
    "        # Convert 2D point to 3D using depth information\n",
    "        point_2d = np.array([[center_x, center_y]], dtype=np.float32)\n",
    "        point_3d = cv2.undistortPoints(point_2d, camera_matrix, dist_coeffs)\n",
    "        point_3d = point_3d[0][0]\n",
    "        point_3d = np.array([point_3d[0], point_3d[1], 1.0]) * depth_value\n",
    "\n",
    "        # Project 3D point back to 2D for visualization\n",
    "        rvec = np.zeros(3, dtype=np.float32)\n",
    "        tvec = np.zeros(3, dtype=np.float32)\n",
    "        point_2d_proj, _ = cv2.projectPoints(point_3d.reshape(1, 1, 3), rvec, tvec, camera_matrix, dist_coeffs)\n",
    "        x_proj, y_proj = point_2d_proj[0][0]\n",
    "\n",
    "        # Draw original bounding box\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Draw projected point on the 3D canvas\n",
    "        cv2.circle(canvas_3d, (int(x_proj), int(y_proj)), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Add depth information\n",
    "        cv2.putText(frame, f\"Depth: {depth_value:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # Combine original frame and 3D canvas\n",
    "    combined_frame = cv2.addWeighted(frame, 0.7, canvas_3d, 0.3, 0)\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(combined_frame)\n",
    "\n",
    "    # Display frame count every 30 frames (optional for logging purposes)\n",
    "    frame_count += 1\n",
    "    if frame_count % 30 == 0:\n",
    "        print(f\"Processed frame {frame_count}\")\n",
    "\n",
    "    # Clear the output to prevent cluttering\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Add a small delay if needed (adjust or remove if processing is already fast enough)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Release video and writer objects\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"Video processing complete. Output saved as 'output_video.mp4'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwInUInBcUKk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
